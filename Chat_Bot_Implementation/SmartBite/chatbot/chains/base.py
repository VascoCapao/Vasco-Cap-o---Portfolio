# Import necessary modules and classes
from langchain.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder,
    SystemMessagePromptTemplate,
)
from pydantic import BaseModel, Field

class PromptTemplate(BaseModel):
    """
    Defines templates for system and human messages used in a conversation.

    Attributes:
        system_template (str): Template for the system message in the conversation.
        human_template (str): Template for the human message in the conversation.
    """

    system_template: str = Field(
        description="Template for the system message in the conversation"
    )
    human_template: str = Field(
        description="Template for the human message in the conversation"
    )

def generate_prompt_templates(
    prompt_template: PromptTemplate, memory: bool
) -> ChatPromptTemplate:
    """
    Generate a chat prompt template based on the given templates and memory setting.

    Args:
        prompt_template (PromptTemplate): An instance containing system and human templates.
        memory (bool): A flag indicating whether to include chat history in the prompt.

    Returns:
        ChatPromptTemplate: A configured template with the specified message structure.
    """

    # Create prompt template including chat history if memory is enabled
    if memory:
        prompt = ChatPromptTemplate.from_messages(
            [
                SystemMessagePromptTemplate.from_template(
                    prompt_template.system_template
                ),
                MessagesPlaceholder(variable_name="chat_history"),
                HumanMessagePromptTemplate.from_template(
                    prompt_template.human_template
                ),
            ]
        )
    else:
        # Create prompt template without chat history
        prompt = ChatPromptTemplate.from_messages(
            [
                SystemMessagePromptTemplate.from_template(
                    prompt_template.system_template
                ),
                HumanMessagePromptTemplate.from_template(
                    prompt_template.human_template
                ),
            ]
        )

    return prompt

class ChainBase:
    """
    Base class for chains to ensure consistent initialization and configuration.

    Attributes:
        prompt_template (PromptTemplate): Template for system and human messages.
        prompt (ChatPromptTemplate): Generated prompt template for the chain.
    """

    def __init__(self, system_template: str, human_template: str, memory: bool = False):
        """
        Initialize the chain with system and human templates.

        Args:
            system_template (str): Template for the system message in the chain.
            human_template (str): Template for the human message in the chain.
            memory (bool): Flag to indicate if chat history should be included. Defaults to False.
        """

        self.prompt_template = PromptTemplate(
            system_template=system_template, human_template=human_template
        )
        self.prompt = generate_prompt_templates(self.prompt_template, memory=memory)

    def process_input(self, user_input: str, **kwargs):
        """
        Prepare input data for the chain.

        Args:
            user_input (str): The user's input to process.
            **kwargs: Additional key-value pairs to include in the processed input.

        Returns:
            dict: A dictionary containing the processed input and additional data.
        """

        return {
            "user_input": user_input,
            **kwargs,
        }

    def run_chain(self, llm, inputs: dict):
        """
        Run the chain logic with the given LLM and inputs.

        Args:
            llm: The language model to use for processing the chain.
            inputs (dict): Input data for the chain.

        Returns:
            Any: The response generated by the language model.
        """

        response = llm.run(self.prompt, inputs)
        return response

